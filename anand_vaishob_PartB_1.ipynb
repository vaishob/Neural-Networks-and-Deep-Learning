{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRX6LUnqBpw"
   },
   "source": [
    "# Question B1 (15 marks)\n",
    "\n",
    "Real world datasets often have a mix of numeric and categorical features – this dataset is one example. To build models on such data, categorical features have to be encoded or embedded.\n",
    "\n",
    "PyTorch Tabular is a library that makes it very convenient to build neural networks for tabular data. It is built on top of PyTorch Lightning, which abstracts away boilerplate model training code and makes it easy to integrate other tools, e.g. TensorBoard for experiment tracking.\n",
    "\n",
    "For questions B1 and B2, the following features should be used:   \n",
    "- **Numeric / Continuous** features: dist_to_nearest_stn, dist_to_dhoby, degree_centrality, eigenvector_centrality, remaining_lease_years, floor_area_sqm\n",
    "- **Categorical** features: month, town, flat_model_type, storey_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn0j2MRKqKVs"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jA67PbIY3PnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_tabular[extra]\n",
      "  Downloading pytorch_tabular-1.1.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (2.4.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (2.1.4)\n",
      "Collecting scikit-learn>=1.3.0 (from pytorch_tabular[extra])\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting pytorch-lightning<2.2.0,>=2.0.0 (from pytorch_tabular[extra])\n",
      "  Downloading pytorch_lightning-2.1.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting omegaconf>=2.3.0 (from pytorch_tabular[extra])\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting torchmetrics<1.3.0,>=0.10.0 (from pytorch_tabular[extra])\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorboard!=2.5.0,>2.2.0 (from pytorch_tabular[extra])\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: protobuf<4.26.0,>=3.20.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (3.20.3)\n",
      "Collecting pytorch-tabnet==4.1 (from pytorch_tabular[extra])\n",
      "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: PyYAML<6.1.0,>=5.4 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (6.0.1)\n",
      "Requirement already satisfied: matplotlib>3.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (3.8.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (7.6.5)\n",
      "Collecting einops<0.8.0,>=0.6.0 (from pytorch_tabular[extra])\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: rich>=11.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch_tabular[extra]) (13.3.5)\n",
      "Collecting wandb<0.17.0,>=0.15.0 (from pytorch_tabular[extra])\n",
      "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting plotly<5.19.0,>=5.13.0 (from pytorch_tabular[extra])\n",
      "  Downloading plotly-5.18.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting kaleido<0.3.0,>=0.2.0 (from pytorch_tabular[extra])\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-win_amd64.whl.metadata (15 kB)\n",
      "Collecting captum<0.8.0,>=0.5.0 (from pytorch_tabular[extra])\n",
      "  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch-tabnet==4.1->pytorch_tabular[extra]) (1.11.4)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch-tabnet==4.1->pytorch_tabular[extra]) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (2.8.2)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.3.0->pytorch_tabular[extra])\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     ---------------------------------------- 0.0/117.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 117.0/117.0 kB 3.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->pytorch_tabular[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->pytorch_tabular[extra]) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from plotly<5.19.0,>=5.13.0->pytorch_tabular[extra]) (8.2.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (4.9.0)\n",
      "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from rich>=11.0.0->pytorch_tabular[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from rich>=11.0.0->pytorch_tabular[extra]) (2.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.0->pytorch_tabular[extra]) (1.2.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->pytorch_tabular[extra])\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (2.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.1.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (3.1.37)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setproctitle (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (1.4.4)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipywidgets->pytorch_tabular[extra]) (6.28.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipywidgets->pytorch_tabular[extra]) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipywidgets->pytorch_tabular[extra]) (5.7.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipywidgets->pytorch_tabular[extra]) (5.9.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipywidgets->pytorch_tabular[extra]) (3.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipywidgets->pytorch_tabular[extra]) (8.20.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipywidgets->pytorch_tabular[extra]) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (3.9.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (4.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (6.3.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (3.0.43)\n",
      "Requirement already satisfied: stack-data in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.0.0->pytorch_tabular[extra]) (0.1.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pytorch_tabular[extra]) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pytorch_tabular[extra]) (4.19.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (2.1.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (6.5.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->pytorch_tabular[extra]) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch_tabular[extra]) (1.9.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb<0.17.0,>=0.15.0->pytorch_tabular[extra]) (4.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pytorch_tabular[extra]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pytorch_tabular[extra]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pytorch_tabular[extra]) (0.10.6)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (305.1)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (21.3.0)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (7.10.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.14.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (1.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets->pytorch_tabular[extra]) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (2.10.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (1.2.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (2.0.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (21.2.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (4.2.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.4.4)\n",
      "Requirement already satisfied: overrides in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (7.4.0)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.58.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (0.1.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra])\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra])\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (2.1)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra])\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra])\n",
      "  Downloading webcolors-24.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\vaishob\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular[extra]) (1.2.3)\n",
      "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/44.5 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 41.0/44.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.2/1.3 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.6/44.6 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading kaleido-0.2.1-py2.py3-none-win_amd64.whl (65.9 MB)\n",
      "   ---------------------------------------- 0.0/65.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/65.9 MB 7.9 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.6/65.9 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.8/65.9 MB 7.0 MB/s eta 0:00:10\n",
      "    --------------------------------------- 1.1/65.9 MB 6.3 MB/s eta 0:00:11\n",
      "    --------------------------------------- 1.1/65.9 MB 6.3 MB/s eta 0:00:11\n",
      "    --------------------------------------- 1.1/65.9 MB 6.3 MB/s eta 0:00:11\n",
      "    --------------------------------------- 1.1/65.9 MB 6.3 MB/s eta 0:00:11\n",
      "    --------------------------------------- 1.1/65.9 MB 6.3 MB/s eta 0:00:11\n",
      "    --------------------------------------- 1.3/65.9 MB 3.2 MB/s eta 0:00:21\n",
      "    --------------------------------------- 1.3/65.9 MB 3.2 MB/s eta 0:00:21\n",
      "    --------------------------------------- 1.3/65.9 MB 3.2 MB/s eta 0:00:21\n",
      "    --------------------------------------- 1.3/65.9 MB 3.2 MB/s eta 0:00:21\n",
      "    --------------------------------------- 1.5/65.9 MB 2.6 MB/s eta 0:00:26\n",
      "    --------------------------------------- 1.6/65.9 MB 2.5 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 1.9/65.9 MB 2.7 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 2.2/65.9 MB 3.0 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 2.4/65.9 MB 3.1 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 2.8/65.9 MB 3.4 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 3.3/65.9 MB 3.8 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 3.8/65.9 MB 4.1 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 4.3/65.9 MB 4.4 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 4.9/65.9 MB 4.8 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 5.0/65.9 MB 4.7 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 5.5/65.9 MB 5.0 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 6.2/65.9 MB 5.3 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 6.2/65.9 MB 5.1 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 6.7/65.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 7.2/65.9 MB 5.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 7.8/65.9 MB 5.8 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 8.5/65.9 MB 6.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 8.8/65.9 MB 6.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 9.2/65.9 MB 6.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 9.9/65.9 MB 6.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 10.7/65.9 MB 6.8 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 11.4/65.9 MB 8.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 12.2/65.9 MB 7.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 12.4/65.9 MB 7.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 12.8/65.9 MB 8.0 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 13.6/65.9 MB 8.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 14.2/65.9 MB 8.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 15.2/65.9 MB 8.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 15.2/65.9 MB 8.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 15.2/65.9 MB 8.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 15.2/65.9 MB 8.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 15.5/65.9 MB 7.7 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 16.2/65.9 MB 7.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 16.7/65.9 MB 8.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 17.2/65.9 MB 8.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 17.4/65.9 MB 8.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 17.4/65.9 MB 8.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 17.4/65.9 MB 8.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 17.4/65.9 MB 8.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 17.7/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 4.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 18.5/65.9 MB 4.5 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 18.6/65.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 18.6/65.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 18.7/65.9 MB 4.3 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 18.9/65.9 MB 4.2 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 19.0/65.9 MB 4.3 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 19.2/65.9 MB 4.2 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 19.2/65.9 MB 4.2 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 19.3/65.9 MB 4.1 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 19.3/65.9 MB 4.1 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 19.3/65.9 MB 3.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 19.4/65.9 MB 3.8 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 19.4/65.9 MB 3.8 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 19.4/65.9 MB 3.7 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 19.4/65.9 MB 3.7 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 19.4/65.9 MB 3.7 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 19.4/65.9 MB 3.7 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 20.2/65.9 MB 3.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 20.5/65.9 MB 3.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 21.3/65.9 MB 3.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 21.7/65.9 MB 3.9 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.6/65.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.7/65.9 MB 2.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 22.8/65.9 MB 1.6 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 23.1/65.9 MB 1.6 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 23.2/65.9 MB 1.6 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 23.5/65.9 MB 1.6 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 23.5/65.9 MB 1.6 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 23.6/65.9 MB 1.5 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 24.0/65.9 MB 1.5 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 24.0/65.9 MB 1.5 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 24.5/65.9 MB 1.5 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 24.5/65.9 MB 1.5 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 25.1/65.9 MB 1.5 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 25.5/65.9 MB 1.5 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 26.2/65.9 MB 1.5 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 27.0/65.9 MB 1.6 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 27.3/65.9 MB 1.5 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 27.8/65.9 MB 1.6 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 27.9/65.9 MB 1.6 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 28.4/65.9 MB 1.6 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 29.1/65.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 29.8/65.9 MB 2.0 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 30.3/65.9 MB 2.0 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 31.2/65.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 32.0/65.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 32.7/65.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 32.9/65.9 MB 9.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 32.9/65.9 MB 9.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 32.9/65.9 MB 9.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 32.9/65.9 MB 9.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 34.0/65.9 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 34.0/65.9 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 34.0/65.9 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 34.0/65.9 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 34.5/65.9 MB 9.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 35.2/65.9 MB 9.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 36.0/65.9 MB 9.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 36.6/65.9 MB 9.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 37.3/65.9 MB 10.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 37.4/65.9 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 37.8/65.9 MB 9.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 38.3/65.9 MB 9.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 38.5/65.9 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 38.6/65.9 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 38.6/65.9 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 39.4/65.9 MB 8.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 39.9/65.9 MB 8.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 40.6/65.9 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.2/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 41.4/65.9 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 41.4/65.9 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 41.4/65.9 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 41.4/65.9 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 41.4/65.9 MB 2.8 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 41.5/65.9 MB 2.6 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 41.5/65.9 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 41.6/65.9 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 41.7/65.9 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 41.9/65.9 MB 2.5 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 42.0/65.9 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 42.1/65.9 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 42.2/65.9 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 42.3/65.9 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 42.4/65.9 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 42.4/65.9 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 42.4/65.9 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 42.4/65.9 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 42.5/65.9 MB 2.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 43.0/65.9 MB 2.2 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.5/65.9 MB 2.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 2.0 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 43.6/65.9 MB 1.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.6/65.9 MB 1.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.6/65.9 MB 1.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.6/65.9 MB 1.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.6/65.9 MB 1.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.6/65.9 MB 1.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.7/65.9 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 43.8/65.9 MB 1.6 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 43.9/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.0/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.1/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.1/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.2/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.2/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.3/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.3/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.3/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.4/65.9 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 44.4/65.9 MB 1.4 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 44.7/65.9 MB 1.4 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 45.5/65.9 MB 1.4 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 46.2/65.9 MB 1.4 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 47.1/65.9 MB 1.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 47.9/65.9 MB 1.5 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 48.7/65.9 MB 1.5 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 49.3/65.9 MB 1.5 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 50.1/65.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 50.7/65.9 MB 1.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 51.7/65.9 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 52.3/65.9 MB 2.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 52.9/65.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.0/65.9 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.1/65.9 MB 2.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.3/65.9 MB 2.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.6/65.9 MB 2.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 53.9/65.9 MB 4.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 54.4/65.9 MB 5.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 55.2/65.9 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 55.8/65.9 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 55.9/65.9 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 56.4/65.9 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 56.7/65.9 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 57.2/65.9 MB 5.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 57.8/65.9 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 58.1/65.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 58.5/65.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 58.5/65.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 59.0/65.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 59.2/65.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 59.2/65.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 59.4/65.9 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 59.4/65.9 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 60.1/65.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 60.5/65.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 61.4/65.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 62.2/65.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 63.0/65.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 63.9/65.9 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  64.8/65.9 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  65.7/65.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  65.9/65.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  65.9/65.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  65.9/65.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 65.9/65.9 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "   ---------------------------------------- 0.0/79.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 79.5/79.5 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.6 MB 21.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 1.1/15.6 MB 17.1 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.7/15.6 MB 2.8 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.7/15.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.8/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 2.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 1.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 977.5 kB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 1.9/15.6 MB 949.8 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 967.6 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 2.0/15.6 MB 815.9 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.1/15.6 MB 816.9 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.1/15.6 MB 816.9 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.2/15.6 MB 823.1 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.2/15.6 MB 823.1 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.3/15.6 MB 834.3 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.3/15.6 MB 841.5 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.4/15.6 MB 840.9 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.4/15.6 MB 853.3 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.5/15.6 MB 866.5 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.6/15.6 MB 887.4 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.7/15.6 MB 905.6 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.8/15.6 MB 917.5 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 2.8/15.6 MB 926.0 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 3.0/15.6 MB 942.2 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 3.1/15.6 MB 974.9 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 3.2/15.6 MB 998.9 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 3.4/15.6 MB 1.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 3.4/15.6 MB 1.0 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 3.7/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 3.8/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 3.9/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 4.0/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 4.1/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 4.2/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 4.3/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.4/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.5/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 4.5/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 4.6/15.6 MB 1.1 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 4.8/15.6 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 4.8/15.6 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 4.9/15.6 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 5.1/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 5.2/15.6 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 5.2/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 5.3/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 5.5/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 5.5/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 5.5/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 5.6/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 5.7/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 5.8/15.6 MB 1.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 6.1/15.6 MB 1.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 6.1/15.6 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.3/15.6 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.5/15.6 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 6.5/15.6 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.8/15.6 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 7.0/15.6 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.5/15.6 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 7.6/15.6 MB 1.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.9/15.6 MB 1.5 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.2/15.6 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.6/15.6 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.1/15.6 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.7/15.6 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 10.3/15.6 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.7/15.6 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.7/15.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.6 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.7/15.6 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.8/15.6 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 12.1/15.6 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.8/15.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.6/15.6 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading pytorch_lightning-2.1.4-py3-none-any.whl (778 kB)\n",
      "   ---------------------------------------- 0.0/778.1 kB ? eta -:--:--\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------- 389.1/778.1 kB 12.2 MB/s eta 0:00:01\n",
      "   -------------------- ----------------- 409.6/778.1 kB 913.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 778.1/778.1 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.0 MB 5.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/11.0 MB 7.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/11.0 MB 9.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 10.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.3/11.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.6/11.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/11.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.8/11.0 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.4/11.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.0/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.4/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.0 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.0/11.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.5/11.0 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.9/11.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 7.5 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.9/5.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.8/5.5 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "   ---------------------------------------- 0.0/806.1 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 92.2/806.1 kB 5.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 225.3/806.1 kB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 491.5/806.1 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 806.1/806.1 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 16.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading pytorch_tabular-1.1.0-py2.py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 160.4/160.4 kB 10.0 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.6/4.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.8/4.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.2/4.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.5/4.3 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.2/4.3 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.0/4.3 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
      "Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl (313 kB)\n",
      "   ---------------------------------------- 0.0/313.8 kB ? eta -:--:--\n",
      "   --------------------------------------  307.2/313.8 kB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 313.8/313.8 kB 9.8 MB/s eta 0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl (11 kB)\n",
      "Downloading webcolors-24.8.0-py3-none-any.whl (15 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144578 sha256=ee96e4a828fad2d4226b987dbd5596d066e2a727025a9ac165b99b9d6126f207\n",
      "  Stored in directory: c:\\users\\vaishob\\appdata\\local\\pip\\cache\\wheels\\1a\\97\\32\\461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: kaleido, antlr4-python3-runtime, webcolors, uri-template, threadpoolctl, tensorboard-data-server, setproctitle, sentry-sdk, plotly, omegaconf, lightning-utilities, grpcio, fqdn, einops, docker-pycreds, absl-py, tensorboard, scikit-learn, wandb, torchmetrics, pytorch-tabnet, isoduration, captum, pytorch-lightning, pytorch_tabular\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 5.9.0\n",
      "    Uninstalling plotly-5.9.0:\n",
      "      Successfully uninstalled plotly-5.9.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed absl-py-2.1.0 antlr4-python3-runtime-4.9.3 captum-0.7.0 docker-pycreds-0.4.0 einops-0.7.0 fqdn-1.5.1 grpcio-1.66.2 isoduration-20.11.0 kaleido-0.2.1 lightning-utilities-0.11.7 omegaconf-2.3.0 plotly-5.18.0 pytorch-lightning-2.1.4 pytorch-tabnet-4.1.0 pytorch_tabular-1.1.0 scikit-learn-1.5.2 sentry-sdk-2.16.0 setproctitle-1.3.3 tensorboard-2.18.0 tensorboard-data-server-0.7.2 threadpoolctl-3.5.0 torchmetrics-1.2.1 uri-template-1.3.0 wandb-0.16.6 webcolors-24.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_tabular[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Jr6P3U7w3NVl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGyEWcVlqKTz"
   },
   "source": [
    "1.Divide the dataset (‘hdb_price_prediction.csv’) into train, validation and test sets by using entries from year 2019 and before as training data, year 2020 as validation data and year 2021 as test data.\n",
    "**Do not** use data from year 2022 and year 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hoCPcOWupw5Y"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# Step 2: Train-Validation-Test Split\n",
    "# Using entries from year 2019 and before as training data, year 2020 as validation data, and year 2021 as test data\n",
    "df = df[df['year'].isin([2019, 2020, 2021])]\n",
    "train_data = df[df['year'] <= 2019]\n",
    "val_data = df[df['year'] == 2020]\n",
    "test_data = df[df['year'] == 2021]\n",
    "\n",
    "# Drop unused columns\n",
    "train_data = train_data.drop(columns=['full_address', 'nearest_stn', 'year'])\n",
    "val_data = val_data.drop(columns=['full_address', 'nearest_stn', 'year'])\n",
    "test_data = test_data.drop(columns=['full_address', 'nearest_stn', 'year'])\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sebMgSuzqPe7"
   },
   "source": [
    "2.Refer to the documentation of **PyTorch Tabular** and perform the following tasks: https://pytorch-tabular.readthedocs.io/en/latest/#usage\n",
    "- Use **[DataConfig](https://pytorch-tabular.readthedocs.io/en/latest/data/)** to define the target variable, as well as the names of the continuous and categorical variables.\n",
    "- Use **[TrainerConfig](https://pytorch-tabular.readthedocs.io/en/latest/training/)** to automatically tune the learning rate. Set batch_size to be 1024 and set max_epoch as 50.\n",
    "- Use **[CategoryEmbeddingModelConfig](https://pytorch-tabular.readthedocs.io/en/latest/models/#category-embedding-model)** to create a feedforward neural network with 1 hidden layer containing 50 neurons.\n",
    "- Use **[OptimizerConfig](https://pytorch-tabular.readthedocs.io/en/latest/optimizer/)** to choose Adam optimiser. There is no need to set the learning rate (since it will be tuned automatically) nor scheduler.\n",
    "- Use **[TabularModel](https://pytorch-tabular.readthedocs.io/en/latest/tabular_model/)** to initialise the model and put all the configs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZZWAYdNhqPzh",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">976</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:44\u001b[0m,\u001b[1;36m976\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">025</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:45\u001b[0m,\u001b[1;36m025\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">048</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:45\u001b[0m,\u001b[1;36m048\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">148</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:45\u001b[0m,\u001b[1;36m148\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">211</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:45\u001b[0m,\u001b[1;36m211\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">394</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">630</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:45\u001b[0m,\u001b[1;36m394\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m630\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: C:\\Users\\Vaishob\\Downloads\\lightning_logs\n",
      "C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:293: The number of training batches (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1e063d51f14c0db175d0ed2d5b5c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at C:\\Users\\Vaishob\\Downloads\\.lr_find_ba145bdf-4b84-49b9-9614-dc1d537366b6.ckpt\n",
      "C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:56: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Restored all states from the checkpoint at C:\\Users\\Vaishob\\Downloads\\.lr_find_ba145bdf-4b84-49b9-9614-dc1d537366b6.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:54</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">781</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5754399373371567</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:54\u001b[0m,\u001b[1;36m781\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m643\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.5754399373371567\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:54</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:24:54\u001b[0m,\u001b[1;36m784\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  2.9 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  2.9 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.5 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.5 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.5 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.5 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939366e8817c4424b6e2a7fafda4bcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:25:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">695</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:25:29\u001b[0m,\u001b[1;36m695\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:25:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">700</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m22:25:29\u001b[0m,\u001b[1;36m700\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f92ebab5984840ab69de4b9613fe34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\pytorch_tabular\\utils\\python_utils.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       6833449984.0        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       6833449984.0        </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      6833449984.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      6833449984.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 3: Configuring Data\n",
    "continuous_cols = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n",
    "categorical_cols = ['month', 'town', 'flat_model_type', 'storey_range']\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['resale_price'],\n",
    "    continuous_cols=continuous_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    ")\n",
    "\n",
    "# Step 4: Trainer Configuration\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    batch_size=1024,\n",
    "    max_epochs=50,\n",
    ")\n",
    "\n",
    "# Step 5: Model Configuration\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"50\",\n",
    "    activation=\"ReLU\",\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# Step 6: Optimizer Configuration\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"Adam\"\n",
    ")\n",
    "\n",
    "# Step 7: Initialize the Model\n",
    "model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "# Step 8: Train the Model\n",
    "model.fit(train=train_data, validation=val_data)\n",
    "\n",
    "# Step 9: Evaluate the Model on Test Data\n",
    "test_result = model.evaluate(test=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">01:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">997</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1533</span><span style=\"font-weight: bold\">}</span> - WARNING - Directory is not empty. Overwriting the \n",
       "contents.                                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m12\u001b[0m \u001b[1;92m01:38:45\u001b[0m,\u001b[1;36m997\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1533\u001b[0m\u001b[1m}\u001b[0m - WARNING - Directory is not empty. Overwriting the \n",
       "contents.                                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save_model(\"deep_learning_model_b1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2UXPKq0qWQG"
   },
   "source": [
    "3.Report the test RMSE error and the test R2 value that you obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zmE9Bc7Nqadi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 82664.68508837765\n",
      "Test R2: 0.7416655778912187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaishob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE & RESULT HERE\n",
    "\n",
    "# Calculate RMSE and R2 on Test Set\n",
    "y_true = test_data['resale_price'].values\n",
    "y_pred = model.predict(test_data.drop(columns=['resale_price']))\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test RMSE: {rmse}')\n",
    "print(f'Test R2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEJhRU18qX22"
   },
   "source": [
    "4.Print out the corresponding rows in the dataframe for the top 25 test samples with the largest errors. Identify a trend in these poor predictions and suggest a way to reduce these errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5ma5K9vKqZEq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month             town  dist_to_nearest_stn  dist_to_dhoby  \\\n",
      "105372      2       QUEENSTOWN             0.570988       4.922054   \n",
      "105869      8       QUEENSTOWN             0.554599       4.841933   \n",
      "92405      11      BUKIT MERAH             0.581977       2.309477   \n",
      "106192     12       QUEENSTOWN             0.658035       3.807573   \n",
      "105702      6       QUEENSTOWN             0.245207       4.709043   \n",
      "92442      11      BUKIT MERAH             0.686789       2.664024   \n",
      "106057     10       QUEENSTOWN             0.584731       3.882019   \n",
      "100836      6  KALLANG/WHAMPOA             0.998313       3.304953   \n",
      "105695      6       QUEENSTOWN             0.745596       3.720593   \n",
      "92504      12      BUKIT MERAH             0.468378       2.365532   \n",
      "90957       6      BUKIT BATOK             1.292540      10.763777   \n",
      "105696      6       QUEENSTOWN             0.658035       3.807573   \n",
      "114389     10        WOODLANDS             0.419275      16.945885   \n",
      "92340      10      BUKIT MERAH             0.451387       2.128424   \n",
      "91871       6      BUKIT MERAH             0.693391       2.058774   \n",
      "92299      10      BUKIT MERAH             0.490926       2.278805   \n",
      "105699      6       QUEENSTOWN             0.745596       3.720593   \n",
      "105468      3       QUEENSTOWN             0.701852       3.763948   \n",
      "91694       4      BUKIT MERAH             0.481551       2.262574   \n",
      "112128     12         TAMPINES             0.370873      12.479752   \n",
      "88081       8       ANG MO KIO             0.860056       7.263401   \n",
      "106132     11       QUEENSTOWN             0.197249       5.421535   \n",
      "106190     12       QUEENSTOWN             0.584731       3.882019   \n",
      "105622      5       QUEENSTOWN             0.379482       6.141343   \n",
      "91908       6      BUKIT MERAH             0.221328       2.322012   \n",
      "\n",
      "        degree_centrality  eigenvector_centrality  \\\n",
      "105372           0.016807                0.005350   \n",
      "105869           0.016807                0.008342   \n",
      "92405            0.016807                0.047782   \n",
      "106192           0.016807                0.008342   \n",
      "105702           0.016807                0.008342   \n",
      "92442            0.016807                0.047782   \n",
      "106057           0.016807                0.008342   \n",
      "100836           0.016807                0.053004   \n",
      "105695           0.016807                0.008342   \n",
      "92504            0.016807                0.047782   \n",
      "90957            0.016807                0.000217   \n",
      "105696           0.016807                0.008342   \n",
      "114389           0.016807                0.000024   \n",
      "92340            0.016807                0.047782   \n",
      "91871            0.016807                0.047782   \n",
      "92299            0.016807                0.047782   \n",
      "105699           0.016807                0.008342   \n",
      "105468           0.016807                0.008342   \n",
      "91694            0.016807                0.047782   \n",
      "112128           0.033613                0.000229   \n",
      "88081            0.016807                0.006243   \n",
      "106132           0.016807                0.005350   \n",
      "106190           0.016807                0.008342   \n",
      "105622           0.033613                0.007356   \n",
      "91908            0.016807                0.047782   \n",
      "\n",
      "                       flat_model_type  remaining_lease_years  floor_area_sqm  \\\n",
      "105372                 4 ROOM, Terrace              46.916667           134.0   \n",
      "105869                 4 ROOM, Terrace              46.416667           120.0   \n",
      "92405                 3 ROOM, Standard              50.166667            88.0   \n",
      "106192  4 ROOM, Premium Apartment Loft              93.333333           109.0   \n",
      "105702            EXECUTIVE, Apartment              73.416667           148.0   \n",
      "92442                 5 ROOM, Improved              90.333333           113.0   \n",
      "106057  4 ROOM, Premium Apartment Loft              93.500000            97.0   \n",
      "100836                 3 ROOM, Terrace              50.083333           210.0   \n",
      "105695  4 ROOM, Premium Apartment Loft              93.916667            97.0   \n",
      "92504                 3 ROOM, Standard              50.166667            88.0   \n",
      "90957             EXECUTIVE, Apartment              75.583333           144.0   \n",
      "105696  4 ROOM, Premium Apartment Loft              93.916667           109.0   \n",
      "114389            EXECUTIVE, Apartment              71.250000           189.0   \n",
      "92340                 5 ROOM, Improved              90.750000           114.0   \n",
      "91871                 3 ROOM, Standard              50.583333            88.0   \n",
      "92299                 3 ROOM, Standard              50.333333            88.0   \n",
      "105699  4 ROOM, Premium Apartment Loft              93.916667           109.0   \n",
      "105468  4 ROOM, Premium Apartment Loft              94.166667            95.0   \n",
      "91694                 3 ROOM, Standard              50.833333            88.0   \n",
      "112128           EXECUTIVE, Maisonette              61.750000           148.0   \n",
      "88081                 5 ROOM, Improved              90.166667           121.0   \n",
      "106132                5 ROOM, Improved              92.333333           117.0   \n",
      "106190  4 ROOM, Premium Apartment Loft              93.333333            97.0   \n",
      "105622                5 ROOM, Improved              90.416667           117.0   \n",
      "91908                 5 ROOM, Improved              93.666667           112.0   \n",
      "\n",
      "       storey_range  resale_price  predicted_resale_price         error  \n",
      "105372     01 TO 03      975000.0            382072.06250  592927.93750  \n",
      "105869     01 TO 03      930000.0            362290.65625  567709.34375  \n",
      "92405      01 TO 03      780000.0            329994.12500  450005.87500  \n",
      "106192     04 TO 06      968000.0            570259.31250  397740.68750  \n",
      "105702     10 TO 12     1235000.0            855073.81250  379926.18750  \n",
      "92442      16 TO 18     1165000.0            792572.31250  372427.68750  \n",
      "106057     13 TO 15      958000.0            590888.06250  367111.93750  \n",
      "100836     01 TO 03     1268000.0            902814.31250  365185.68750  \n",
      "105695     07 TO 09      930000.0            565008.06250  364991.93750  \n",
      "92504      01 TO 03      695000.0            336434.81250  358565.18750  \n",
      "90957      10 TO 12      968000.0            609733.81250  358266.18750  \n",
      "105696     10 TO 12      950000.0            593405.50000  356594.50000  \n",
      "114389     04 TO 06      980000.0            623969.75000  356030.25000  \n",
      "92340      34 TO 36     1245000.0            889729.87500  355270.12500  \n",
      "91871      01 TO 03      680888.0            326317.43750  354570.56250  \n",
      "92299      01 TO 03      690000.0            335766.84375  354233.15625  \n",
      "105699     31 TO 33     1032888.0            682908.93750  349979.06250  \n",
      "105468     10 TO 12      920000.0            572052.81250  347947.18750  \n",
      "91694      01 TO 03      680000.0            337015.12500  342984.87500  \n",
      "112128     01 TO 03      998000.0            662433.12500  335566.87500  \n",
      "88081      28 TO 30     1100000.0            765080.93750  334919.06250  \n",
      "106132     34 TO 36     1230000.0            898525.18750  331474.81250  \n",
      "106190     16 TO 18      938888.0            609778.50000  329109.50000  \n",
      "105622     34 TO 36     1210000.0            882936.31250  327063.68750  \n",
      "91908      22 TO 24     1205500.0            879213.37500  326286.62500  \n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE & RESULT HERE\n",
    "\n",
    "# Step 10: Print Top 25 Test Samples with Largest Errors\n",
    "test_data['predicted_resale_price'] = y_pred\n",
    "test_data['error'] = abs(test_data['resale_price'] - test_data['predicted_resale_price'])\n",
    "sorted_test_data = test_data.sort_values(by='error', ascending=False)\n",
    "print(sorted_test_data.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX5zy7V3qaGp"
   },
   "source": [
    "Observing the top 25 samples with the largest errors shows that the model struggles particularly with certain towns like Queenstown and Bukit Merah, as well as flats with larger floor areas or those on lower floors.\n",
    "\n",
    "Possible trends include:\n",
    "- Flats in popular towns (e.g., Queenstown, Bukit Merah) with high demand may have more volatile prices that are difficult to predict.\n",
    "- Flats on lower floors tend to have larger errors, possibly because the price variation across floors is not well captured.\n",
    "- Large floor area or executive flats also have larger errors, indicating the model might struggle to generalize well for larger properties.\n",
    " \n",
    "Suggestion: To reduce errors, I would consider adding more relevant features such as the age of the building, proximity to amenities like schools or parks, or incorporating external factors like economic indicators. Additionally, I would consider increasing model complexity, tuning hyperparameters further, or using more advanced models like Gradient Boosting or XGBoost to help capture non-linear relationships better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOG8ZhA98h3O6fnefkjOU9w",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
